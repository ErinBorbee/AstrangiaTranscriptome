{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c514baf9",
   "metadata": {},
   "source": [
    "# Astrangia poculata transcriptome assembly\n",
    "\n",
    "This notebook contains the code for the *Astrangia poculata* reference transcriptome assembly. This is a de novo assembly constructed using data from RNAseq (Illumina). The coral colonies used to extract the RNA for this assembly were collected from Fort Wetherhill State Park in Jamestown, RI. Additionally, since *A. poculata* is a facultatively symbiotic coral, the colonies used to generate the assembly were from 10 brown and white individuals (5 brown, 5 white). These colonies we previously used in an experiment where some were exposed to a heat-killed pathogen and others were left unexposed. The final breakdown of individuals used in this assembly was 2 brown control, 2 white control, 3 brown pathogen-exposed, 3 white pathogen-exposed. \n",
    "\n",
    "The total input for the assembly was 219,350,638 reads and the final assembly consisted of 158,336 transcripts. The best quality assembly was done using Trinity. Multiple iterations of this assembly were done using different assemblers and methods including short read assemblies (RNAeq - Illumina), long read assemblies (IsoSeq - PacBio), and hybrid assemblies (both short and long read data). We also ran iterations with different number of samples for input and different sample combinations. Below is the code used to generate our highest quality assembly and notes on the data from each step.\n",
    "<a id=\"0\"></a> <br>\n",
    "### Contents\n",
    "#### [1. Installing programs](#1)\n",
    "#### [2. Adapter and quality trimming](#2) \n",
    "#### [3. Symbiont read filtering](#3)\n",
    "#### [4. Concatenating reads for assembly](#4)\n",
    "#### [5. Transcriptome assembly](#5)\n",
    "#### [6. Quality assessment of assembly](#6)\n",
    "#### [7. Assembly filtering](#7)\n",
    "#### [8. Annotations](#8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc0ef5",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1. Program installation\n",
    "For this pipeline you will need cutadapt, BBMap, Bowtie2, Trinity, Salmon, and\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a09c7",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2. Adapter and quality trimming\n",
    "Raw sequence files were quality assessed using FastQC. Each sequence file was then trimmed using cutadapt to trim adapter sequences off the ends of reads, and remove low quality sequences (average Phred score <20), and sequences with N base calls.\n",
    "\n",
    "The first line of code runs FastQC on all `.fastq` files in the directory where the sequence data is located. The second code runs `cutadapt` in array on all sequence files. The cutadapt code provided is the bash script written to be run in array format on the LEAP2 server at Texas State. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77297897",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqc *.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=cutadapt\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=shared\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --array=103-112%10\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o cutadapt_%j.out\n",
    "#SBATCH -e cutadapt_%j.err\n",
    "\n",
    "cutadapt -a AGATCGGAAGAG -m 25  -q 20 --untrimmed-output EB_${SLURM_ARRAY_TASK_ID}_1_untrimmed.fastq \\\n",
    "--untrimmed-paired-output EB_${SLURM_ARRAY_TASK_ID}_2_untrimmed.fastq -o EB_${SLURM_ARRAY_TASK_ID}_1_trimmed.fastq \\\n",
    "-p EB_${SLURM_ARRAY_TASK_ID}_2_trimmed.fastq EB_${SLURM_ARRAY_TASK_ID}_1.fq EB_${SLURM_ARRAY_TASK_ID}_2.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f80e8",
   "metadata": {},
   "source": [
    "In this cutadapt script, the `-a` provides the 3' adapter sequence, the `-m` is the minimum sequence length, the `-q` is the minimum Phred quality score for each sequence, `untrimmed-output` is the forward reads that did not contain the adapter and therefore were not trimmed, `--untrimmed-paired-output` is the same as the untrimmed output but for the reverse read, `-o` is the output for the forward read, and `-p` is the output for the reverse read. Rather than run multiple commands for each sample, this script is run by designating the sample IDs from the file name in the script header using `#SBATCH --array=[SAMPLE_#s]`. The `%10` at the end of the array designation in the header tells the job manager how many jobs to run simultaneously. So to avoid running too many simultaneously, this number should never be larger than 10. The last step in setting up the array is replacing the sample number portion of the filenames with `${SLURM_ARRAY_TASK_ID}`. \n",
    "\n",
    "Since not all reads contained the adapter, the trimmed outputs were concatenated to the untrimmed outputs to avoid data loss. Short and low quality reads remained removed from the sequences in this step. We combined these two files using the `cat` command. Below is the bash script that was submitted on the LEAP2 server at Texas State University using an array as explained above in the cutadapt script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=concatenate\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=shared\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --array=103-112%10\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o concatenate_%j.out\n",
    "#SBATCH -e concatenate_%j.err\n",
    "\n",
    "cat EB_${SLURM_ARRAY_TASK_ID}_1_trimmed.fastq EB_${SLURM_ARRAY_TASK_ID}_1_untrimmed.fastq > EB_${SLURM_ARRAY_TASK_ID}_1_cat.fastq\n",
    "\n",
    "cat EB_${SLURM_ARRAY_TASK_ID}_2_trimmed.fastq EB_${SLURM_ARRAY_TASK_ID}_2_untrimmed.fastq > EB_${SLURM_ARRAY_TASK_ID}_2_cat.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a6949",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3. Symbiont read filtering\n",
    "Coral RNA extractions extract both coral host and algal symbiont RNA. So after trimming adapter sequences, we then filtered our reads to remove symbiont sequences from our data. We did this by using `bbsplit` to map reads to the symbiont (*Breviolum psygmophilum*) reference transcriptome and any reads that don't match the symbiont reference are saved into a new file of just coral reads.\n",
    "\n",
    "The first block of code is the bbsplit script that was used to remove the symbiont reads. Just as with the cutadapt script this script was run in array to remove the symbiont reads from the forward and reverse reads of each sample. The *Breviolum psygmophilum* reference transcriptome that was used for this script was downloaded from Reef Genomics. The paper the transcriptome was pulled from is cited below and the website where the file was downloaded from is also provided. The transcriptome was published prior to the reclassification of *Symbiodinium* so the transcriptome is listed under *Symbiodinium psygmophilum* rather than *Breviolum psygmophilum*.\n",
    "\n",
    "#### Reference:\n",
    "Parkinson, J. E., Baumgarten, S., Michell, C. T., Baums, I. B., LaJeunesse, T. C., & Voolstra, C. R. (2016). Gene expression variation resolves species and individual strains among coral-associated dinoflagellates within the genus *Symbiodinium*. *Genome Biology and Evolution*, 8(3), 665-680.\n",
    "\n",
    "#### *B. psygmophilum* reference transcriptome download link:\n",
    "http://reefgenomics.org/sitemap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=bbsplit\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 13-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --array=103-112\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o bbsplit_%j.out\n",
    "#SBATCH -e bbsplit_%j.err\n",
    "\n",
    "~/miniconda3/envs/trinity/bin/bbsplit.sh ref=~/BrevPsygmophilum_transcriptome/psyg_assembly_longest_250.fa \\\n",
    "in1=EB_${SLURM_ARRAY_TASK_ID}_1_cat.fastq in2=EB_${SLURM_ARRAY_TASK_ID}_2_cat.fastq basename=out_%.fa \\\n",
    "refstats=sampleStats.txt outu1=unmatched_${SLURM_ARRAY_TASK_ID}_reads1.fa \\\n",
    "outu2=unmatched_${SLURM_ARRAY_TASK_ID}_reads2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce3825",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4. Concatenating reads for assembly\n",
    "The output from the bbsplit script is a series of files for each sample titled `unmatched_[SAMPLE_ID]_reads1.fa` and `unmatched_[SAMPLE_ID]_reads2.fa`. The next step is to concatenate the forward and reverse reads from all samples to generate two files, one containing all the forward reads and one containing all the reverse reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=concatenate\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=shared\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o concatenate_%j.out\n",
    "#SBATCH -e concatenate_%j.err\n",
    "\n",
    "cat unmatched_103_reads1.fa unmatched_104_reads1.fa unmatched_105_reads1.fa unmatched_106_reads1.fa \\\n",
    "unmatched_107_reads1.fa unmatched_108_reads1.fa unmatched_109_reads1.fa unmatched_110_reads1.fa \\\n",
    "unmatched_111_reads1.fa unmatched_112_reads1.fa > unmatched_reads1.fa\n",
    "\n",
    "cat unmatched_103_reads2.fa unmatched_104_reads2.fa unmatched_105_reads2.fa unmatched_106_reads2.fa \\\n",
    "unmatched_107_reads2.fa unmatched_108_reads2.fa unmatched_109_reads2.fa unmatched_110_reads2.fa \\\n",
    "unmatched_111_reads2.fa unmatched_112_reads2.fa > unmatched_reads2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417587c",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4. Transcriptome assembly\n",
    "The next step is the transcriptome assembly using Trinity. Trinity uses three phases to construct a de novo transcriptome assembly. For more information about how the Trinity assembly works, the link to their wiki is provided below.\n",
    "\n",
    "#### Trinity wiki:\n",
    "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=trinity\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 27-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=500G\n",
    "#SBATCH --mail-type=FAIL,END\n",
    "#SBATCH --mail-user=loe8@txstate.edu\n",
    "#SBATCH -o trinity_%j.out\n",
    "#SBATCH -e trinity_%j.err\n",
    "\n",
    "Trinity --normalize_reads --seqType fa --grid_node_CPU 21 --grid_node_max_memory 300G --max_memory 300G \\\n",
    "--left ../raw_data/concatenated/unmatched_reads1.fa --right ../raw_data/concatenated/unmatched_reads2.fa  \\\n",
    "--CPU 25 --output trinity_out_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b714b6b",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5. Assembly quality assessment\n",
    "Before filtering, we did a quality assessment of the raw assembly. The quality assessment consisted of counting the number of transcripts, calculating the N50 of the assembly, and assessing the completeness of the assembly using BUSCO. The first command is a simple `grep` command to count the number of transcripts in the raw assembly file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep -c \">\" Trinity.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5b8d8",
   "metadata": {},
   "source": [
    "The total transcript count in the raw assembly is 973,377.\n",
    "\n",
    "The next step in quality assessment was to calculate the N50 of the assembly. The N50 is a metric that tells you the length of the transcript at the middle of the assembly when transcripts are laid in order from shortest to longest. Trinity provides a script for calculating the N50 in the code from their GitHub repository. If you have not downloaded the Trinity GitHub repository, you will need to do that to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020950e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/trinityrnaseq-master/util/TrinityStats.pl Trinity.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b5733",
   "metadata": {},
   "source": [
    "The output from the above command is as follows:\n",
    "\n",
    "\n",
    "`################################\n",
    "\n",
    "##Counts of transcripts, etc.\n",
    "\n",
    "################################\n",
    "\n",
    "Total trinity 'genes':\t818951\n",
    "\n",
    "Total trinity transcripts:\t973377\n",
    "\n",
    "Percent GC: 41.28\n",
    "\n",
    "########################################\n",
    "\n",
    "Stats based on ALL transcript contigs:\n",
    "\n",
    "########################################\n",
    "\n",
    "\tContig N10: 1641\n",
    "\tContig N20: 1071\n",
    "\tContig N30: 732\n",
    "\tContig N40: 518\n",
    "\tContig N50: 389\n",
    "\n",
    "\tMedian contig length: 267\n",
    "\tAverage contig: 394.19\n",
    "\tTotal assembled bases: 383692727\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "##Stats based on ONLY LONGEST ISOFORM per 'GENE':\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\tContig N10: 1160\n",
    "\tContig N20: 675\n",
    "\tContig N30: 466\n",
    "\tContig N40: 363\n",
    "\tContig N50: 298\n",
    "\n",
    "\tMedian contig length: 261\n",
    "\tAverage contig: 338.47\n",
    "\tTotal assembled bases: 277191183`\n",
    "    \n",
    "This output shows that the N50 of the overall assembly is 389, and when assessing only the longest isoforms of each transcript the N50 is 298. Ideally the N50 should be >1000 for a good quality assembly.\n",
    "\n",
    "The last step in the quality assessment is to assess completeness of the assembly using BUSCO. BUSCO stands for Benchmarking Universal Single-Copy Orthologs and compares the transcripts present in the assembly to a database of single copy orthologs for a wide range of taxonomic groups. In this case sequences were compared against the eukaryotic database. The following script was submitted as a job on the LEAP2 server at Texas State."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=busco\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o busco_%j.out\n",
    "#SBATCH -e busco_%j.err\n",
    "\n",
    "busco -i Trinity.fasta  -l ~/AstrangiaTranscriptome_042622/busco_downloads/eukaryota_odb10 \\\n",
    "-o busco_output -m transcriptome --offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9dc04b",
   "metadata": {},
   "source": [
    "The BUSCO output for the raw assembly was as follows:\n",
    "\n",
    "|Category              |Number of BUSCOS|Percentage|\n",
    "-----------------------|----------------|----------|\n",
    "|Complete              |182             |71.3%     |\n",
    "|Complete (single-copy)|46              |18.0%     |\n",
    "|Complete (duplicated) |136             |53.3%     |\n",
    "|Fragmented            |52              |20.4%     |\n",
    "|Missing               |21              |8.3%      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a09abb0",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### 5. Extracting coding sequences\n",
    "Next we filtered our transcriptome to coding sequences by extracting the longest open reading frame from each contig using transdecoder. In the same transdecoder script, we generated a file of predicted peptides for each sequence. The code was submitted as a job on the LEAP2 server at Texas State University in the format provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=transDecoder\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 27-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=500G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=loe8@txstate.edu\n",
    "#SBATCH -o transDecoder_%j.out\n",
    "#SBATCH -e transDecoder_%j.err\n",
    "\n",
    "TransDecoder.LongOrfs -t Trinity.fasta\n",
    "TransDecoder.Predict -t Trinity.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4085d56",
   "metadata": {},
   "source": [
    "The outputs of the script were `Trinity.fasta.transdecoder.cds` containing all of the coding sequences and `Trinity.fasta.transdcoder.pep` containing the predicted peptide sequences. By extracting the coding sequences, we reduced the number of transcripts in the assembly from 973,377 to 218,374.\n",
    "\n",
    "BUSCO was run on the coding sequence file to assess completeness after filtering. The BUSCO code and outputs are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=busco\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o busco_%j.out\n",
    "#SBATCH -e busco_%j.err\n",
    "\n",
    "busco -i Trinity.fasta.transdecoder.cds  -l ~/AstrangiaTranscriptome_042622/busco_downloads/eukaryota_odb10 \\\n",
    "-o busco_cds_output -m transcriptome --offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c2377",
   "metadata": {},
   "source": [
    "BUSCO output for the coding sequences:\n",
    "\n",
    "|Category              |Number of BUSCOS|Percentage|\n",
    "-----------------------|----------------|----------|\n",
    "|Complete              |180             |70.6%     |\n",
    "|Complete (single-copy)|89              |34.9%     |\n",
    "|Complete (duplicated) |91              |35.7%     |\n",
    "|Fragmented            |51              |20.0%     |\n",
    "|Missing               |24              |9.4%      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654cfe89",
   "metadata": {},
   "source": [
    "The N50 of the coding sequence file is as follows:\n",
    "\n",
    "`################################\n",
    "\n",
    "##Counts of transcripts, etc.\n",
    "\n",
    "################################\n",
    "\n",
    "Total trinity 'genes':\t151123\n",
    "\n",
    "Total trinity transcripts:\t218374\n",
    "\n",
    "Percent GC: 44.34\n",
    "\n",
    "########################################\n",
    "\n",
    "Stats based on ALL transcript contigs:\n",
    "\n",
    "########################################\n",
    "\n",
    "\tContig N10: 1527\n",
    "\tContig N20: 1134\n",
    "\tContig N30: 900\n",
    "\tContig N40: 729\n",
    "\tContig N50: 603\n",
    "\n",
    "\tMedian contig length: 438\n",
    "\tAverage contig: 570.98\n",
    "\tTotal assembled bases: 124686990\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "##Stats based on ONLY LONGEST ISOFORM per 'GENE':\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\tContig N10: 1323\n",
    "\tContig N20: 957\n",
    "\tContig N30: 744\n",
    "\tContig N40: 606\n",
    "\tContig N50: 510\n",
    "\n",
    "\tMedian contig length: 405\n",
    "\tAverage contig: 515.90\n",
    "\tTotal assembled bases: 77964321\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc418564",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### 5. Clustering sequences by similarity\n",
    "After extracting coding sequences, we clustered the sequences by similarity using cd-hit to further reduce the size of our transcriptome. The cd-hit code was run on the LEAP2 server at Texas State University using the following script. In this script `-c` represents the sequence identity threshold, `-G` tells the program to either sort the sequence into the first cluster that it meets the threshold for (0) or the most similar cluster (1), `-aL` represents the alignment coverage for the longer sequence, and `-aS` represents the alignment coverage for the shorter sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=cdhit\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=500G\n",
    "#SBATCH --mail-type=FAIL,END\n",
    "#SBATCH --mail-user=loe8@txstate.edu\n",
    "#SBATCH -o trinity_%j.out\n",
    "#SBATCH -e trinity_%j.err\n",
    "\n",
    "cd-hit-est -i Trinity.fasta.transdecoder.cds -o Trinity.transdecoder.cdhit.fasta -c 0.99 -G 0 -aL 0.3 -aS 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770885e",
   "metadata": {},
   "source": [
    "The cd-hit step reduced the transcriptome from 218,374 transcripts to 180,914 transcripts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
