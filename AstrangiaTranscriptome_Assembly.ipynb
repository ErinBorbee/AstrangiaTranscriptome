{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b42b6b",
   "metadata": {},
   "source": [
    "# Astrangia de novo Transcriptome Assembly\n",
    "The following pipeline was used to de novo assemble an *Astrangia poculata* transcriptome from RNAseq data. The following scripts were run on the LEAP server at Texas State University. The code here provides both the commands and the SBATCH parameters for the shell scripts that were submitted to the job manager at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3a04e",
   "metadata": {},
   "source": [
    "## 1. Install programs\n",
    "The following pipeline uses FastQC, MultiQC, Cutadapt, bbmap, bowtie2, Trinity, BUSCO, and bioperl. If these are not already installed, you will need to do that before moving forward. On the LEAP server, these programs can be installed using the following scripts. Some of the provided install commands rely on conda, which can be installed following the instructions on the Miniconda website (https://docs.conda.io/en/latest/miniconda.html). \n",
    "\n",
    "*FastQC*\n",
    "\n",
    "Download the FastQC zipfile (https://www.bioinformatics.babraham.ac.uk/projects/download.html#fastqc) and unzip the file in the location you want it installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip fastqc_v0.11.9.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a41180",
   "metadata": {},
   "source": [
    "*MultiQC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install multiqc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928274f9",
   "metadata": {},
   "source": [
    "*Cutadapt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9935898",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda cutadapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdda7e7",
   "metadata": {},
   "source": [
    "*bbmap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99056570",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda bbmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a4e7b",
   "metadata": {},
   "source": [
    "*Bowtie2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2922306",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda bowtie2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a609f4",
   "metadata": {},
   "source": [
    "*Trinity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda trinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbead76",
   "metadata": {},
   "source": [
    "*BUSCO*\n",
    "\n",
    "BUSCO can be installed using conda following the command below. However, before installing BUSCO you should makes sure you have all of the necessary dependencies installed. For the list of dependencies look on the BUSCO website (https://busco.ezlab.org/busco_userguide.html#manual-installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge -c bioconda busco=5.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd6fdf",
   "metadata": {},
   "source": [
    "*bioperl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77faa001",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda perl-bioperl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2e7e3",
   "metadata": {},
   "source": [
    "## 2. Download data\n",
    "Data was downloaded from Novogene directly to the LEAP server using the `wget` code provided by Novogene. The data was downloaded to a folder designated for the transcriptome data and assembly titled `AstrangiaTranscriptome_042622` and within the transcriptome directory, the sequence files were sorted into a subdirectory titled `raw_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir AstrangiaTranscriptome_042622\n",
    "cd AstrangiaTranscriptome_042622\n",
    "mkdir raw_data\n",
    "cd raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79d06b",
   "metadata": {},
   "source": [
    "## 3. Quality assessment\n",
    "Raw RNAseq files were quality assessed first using FastQC and MultiQC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/FastQC/fastqc ~/AstrangiaTranscriptome_042622/raw_data/EB*.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiqc ~/AstrangiaTranscriptome_042622/raw_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5097960",
   "metadata": {},
   "source": [
    "Once the MultiQC file was generated it was secure copied to my local computer and opened to view the sequence quality plots and statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cc777",
   "metadata": {},
   "source": [
    "## 4. Trimming and quality filtering\n",
    "Sequences were trimmed to remove sequences with high numbers of N base calls and low quality sequences (sequences with average Phred quality scores of <20). The filtering and trimming was done using cutadapt by submitting the following script titled `cutadapt.sh` to the job manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=cutadapt\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=shared\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o trim_%j.out\n",
    "#SBATCH -e trim_%j.err\n",
    "\n",
    "cutadapt --max-n 0 -q 20 -o allReads_1_trimmed.fq -p allReads_2_trimmed.fq allReads_1.fq allReads_2.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c71ce",
   "metadata": {},
   "source": [
    "## 5. Separating host and symbiont reads\n",
    "Before assembling you should start by separating host and symbiont reads into separate files. This is done using `bbsplit` (command from bbmap) and mapping reads to the *Breviolum psygmophilum* reference transcriptome. Reads that map to the transcriptome will sort into one file, while the reads that don't map to the reference will sort into a separate file that will be designated as reads belonging to the host (*Astrangia poculata*). \n",
    "\n",
    "The *Breviolum psygmophilum* reference transcriptome can be accessed on the Reef Genomics database (http://zoox.reefgenomics.org/download/).\n",
    "\n",
    "This process was done by submitting the following code in a script titled `bbsplit.sh` to the job manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=bbsplit\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 13-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o bbsplit_%j.out\n",
    "#SBATCH -e bbsplit_%j.err\n",
    "\n",
    "~/miniconda3/bin/bbsplit.sh ref=~/BrevPsygmophilum_transcriptome/psyg_assembly_longest_250.fa \\\n",
    "in1=allReads_1_trimmed.fq in2=allReads_2_trimmed.fq basename=out_%.fa refstats=sampleStats.txt \\\n",
    "outu1=unmatched_reads1.fa outu2=unmatched_reads2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77681473",
   "metadata": {},
   "source": [
    "The script will result in an output file with the reads mapping to the reference *B. psygmophilum* transcriptome (`out_psyg_assembly_longest_250.fa`), and two files for the forward and reverse files of sequences that did not map to the reference (`unmatched_reads1.fa` and `unmatched_reads2.fa`). The two unmatched files will contain the sequences belonging to *Astraangia poculata* and will be used in the next step for the assembly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78753374",
   "metadata": {},
   "source": [
    "## 6. Transcriptome assembly\n",
    "Once we have the symbiont and host reads separated, we can move into transcriptome assembly with the host reads. To assemble the transcriptome we use the program Trinity. For explanation of how Trinity works, check out their Github page (https://github.com/trinityrnaseq/trinityrnaseq/wiki). This is a computationally heavy step and requires a high memory node on the LEAP server as indicated in the SBATCH parameters in the script. The high memory nodes have max time limits of 60 days. You should plan to request a minimum of 1 month of time to be sure the job has enough time to complete. The assembly can be run by submitting the following script titled `trinity.sh` to the job manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=trinity\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 30-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=500G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o trinity_%j.out\n",
    "#SBATCH -e trinity_%j.err\n",
    "\n",
    "Trinity --seqType fa --max_memory 500G --left unmatched_reads1.fa --right unmatched_reads2.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539ea76",
   "metadata": {},
   "source": [
    "Trinity will generate an output directory titled `trinity_out_dir`. Inside that directory, you will find outputs from each step of the program, and the assembled transcriptome in fasta format titled `Trinity.fa`. The fasta output from Trinity is not in proper fasta format as there are line breaks inserted periodically throughout the sequences. You will need to remove these line breaks before moving forward with the next steps. You can do this with the following awk command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Trinity.fa | awk '{if (substr($0,1,1)==\">\"){if (p){print \"\\n\";} print $0} else printf(\"%s\",$0);p++;}END{print \"\\n\"}' > Trinity_fixed.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1d433",
   "metadata": {},
   "source": [
    "## 7. Evaluating assembly quality\n",
    "### 7.1 Assessment of read content in transcriptome assembly\n",
    "One way to evaluate the quality of a transcriptome assembly is to map reads from your original sequence files back to the newly assembled transcriptome. This can be done using bowtie2 and the following scripts. This will take a few days to run on the LEAP server so be sure to request an appropriate amount of time (I requested 7 days to be safe). More information on this process can be found here: https://github.com/trinityrnaseq/trinityrnaseq/wiki/RNA-Seq-Read-Representation-by-Trinity-Assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ec99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=bowtie\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 6-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o bowtie_%j.out\n",
    "#SBATCH -e bowtie_%j.err\n",
    "\n",
    "bowtie2-build Trinity_fixed.fa Trinity_fixed.fa\n",
    "\n",
    "bowtie2 -p 10 -q --no-unal -k 20 -x Trinity_fixed.fa \\\n",
    "-1 ~/AstrangiaTranscriptome_042622/allReads_1_trimmed.fq \\\n",
    "-2 ~/AstrangiaTranscriptome_042622/allReads_2_trimmed.fq  \\\n",
    "     2>align_stats.txt| samtools view -@10 -Sb -o bowtie2.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b95b8",
   "metadata": {},
   "source": [
    "### 7.2 Evaluating completeness of ortholog content with BUSCO\n",
    "BUSCO allows us to evaluate the completeness of our transcriptome based on the content of highly conserved single-copy orthologs in closely related species. On the LEAP server, we have to run BUSCO in offline mode which means you need to download the lineage dataset and upload it to the server manually. Lineage datasets can be downloaded from the BUSCO website (https://busco-data.ezlab.org/v5/data/lineages/). Once downloaded, you will have to designate the path to the lineage dataset in the BUSCO script. BUSCO can be run by submitting the following script to the job manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ca3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=busco\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 30-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o busco_%j.out\n",
    "#SBATCH -e busco_%j.err\n",
    "\n",
    "busco -i Trinity_fixed.fasta  \\\n",
    "-l ~/AstrangiaTranscriptome_042622/trinityOutput/trinity_out_dir/busco_downloads/eukaryota_odb10 \\\n",
    "-o busco_output -m transcriptome --offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4bbaf",
   "metadata": {},
   "source": [
    "### 7.3 Counting number of transcripts in the assembly\n",
    "The number of transcripts in a good transcriptome assembly should be between 50,000-100,000 reads. To count the number of transcripts in the assembly we can use `fgrep` to count the number of `>` characters in the assembly fasta file using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgrep -c \">\" Trinity_fixed.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c45abb",
   "metadata": {},
   "source": [
    "If you have a high number of transcripts you can try either a genome-guided assembly or using methods detailed below to reduce the number of transcripts by filtering isoforms and other steps. If you do not have a high number of transcripts, skip ahead to the \"Annotating transcriptome\" section of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a762fb",
   "metadata": {},
   "source": [
    "### 7.4 Assembly statistics (N50)\n",
    "N(x) statistics tell you the length of the transcript at X% the total length of the assembly when transcripts are lined up by length order. The statistic most commonly reported in publications is the N50 value. N10, N20, N30, N40, and N50 values can all be calculated using the `Trinity_stats.pl` file found in the `trinityrnaseq` github repository and the script is explained at the link below.\n",
    "\n",
    "https://github.com/trinityrnaseq/trinityrnaseq/wiki/Transcriptome-Contig-Nx-and-ExN50-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b194fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "~/trinityrnaseq/util/Trinity_stats.pl Trinity_fixed.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7962220",
   "metadata": {},
   "source": [
    "## 8. Genome-guided assembly\n",
    "Genome-guided assemblies work similar to *de novo* assemblies with the difference that they use previously assembled genomes for the species of interest as a reference for assembling transcripts. The following section's code was constructed using the script and information provided on the Trinity GitHub page linked below.\n",
    "\n",
    "https://github.com/trinityrnaseq/trinityrnaseq/wiki/Genome-Guided-Trinity-Transcriptome-Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28ad37",
   "metadata": {},
   "source": [
    "### 8.1 Installing additional programs\n",
    "For a genome-guided assembly you will need to provide Trinity with read alignments to the reference genome as a coordinate-sorted `bam` file. This file can be generated using `GSNAP`, `TopHat`, or `STAR`. The code for installing each of these is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c compbiocore gsnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80dbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda tophat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571398e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea8ca4e",
   "metadata": {},
   "source": [
    "### 8.2 Genome-guided assembly\n",
    "The following code has Trinity use GSNAP to align RNAseq reads to the reference genome and then runs the genome-guided assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1b831",
   "metadata": {},
   "outputs": [],
   "source": [
    " Trinity --genome_guided_bam rnaseq.coordSorted.bam \\\n",
    "         --genome_guided_max_intron 10000 \\\n",
    "         --max_memory 10G --CPU 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68e27c",
   "metadata": {},
   "source": [
    "## Annotating transcriptome\n",
    "The steps taken to annotate the new transcriptome assembly were taken from Misha Matz's GitHub (https://github.com/z0on/annotatingTranscriptomes/blob/master/annotating%20trascriptome.txt). To start we need to clone the git repository on our accounts on the LEAP server so we have access to all of the scripts. You will also want to make a directory to store all of the transcriptome annotation files and navigate to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40515291",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://github.com/z0on/annotatingTranscriptomes/archive/master.zip\n",
    "unzip master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir transcriptomeAnnotations\n",
    "cd transcriptomeAnnotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1652160",
   "metadata": {},
   "source": [
    "### Download UniProt database\n",
    "We will annotate the transcriptome using the UniProt database. To do this we have to first download and unzip the UniProt database in a new directory on our LEAP account. Then we will use `makeblastdb` from BLAST to construct the database on the LEAP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9faed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir uniprotDB\n",
    "cd uniprotDB\n",
    "wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
    "gunzip uniprot_sprot.fasta.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "makeblastdb -in uniprot_sprot.fasta -dbtype prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b05d29",
   "metadata": {},
   "source": [
    "### BLAST transcriptome against UniProt database\n",
    "The next step in annotating the transcriptom is BLASTing the sequences against the UniProt database. In order for this process to run quicker we first split the transcriptome into 40 chunks that can then run in parallel. After the BLAST is complete we can combine the outputs back into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c47eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "../annotatingTranscriptomes-master/splitFasta.pl Trinity_fixed.fasta 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07968779",
   "metadata": {},
   "source": [
    "The following perl command will construct all of the necessary BLAST commands for each of the 40 subsets of the transcriptome generated above in place them in a file titled `blast.sh`. Once the commands are generated, you will have to add in the `SBATCH` parameters to the top of the script and then change the permissions to make the script executable using `chmod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f53a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls subset* | perl -pe 's/^(\\S+)$/blastx -query $1 -db uniprot_sprot\\.fasta -evalue 0\\.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out $1.br/'>blast.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=blast\n",
    "#SBATCH -N 1\n",
    "#SBATCH -t 30-24:00\n",
    "#SBATCH --partition=himem\n",
    "#SBATCH --mem=250G\n",
    "#SBATCH --mail-type=end\n",
    "#SBATCH --mail-user=eborbee@txstate.edu\n",
    "#SBATCH -o blast_%j.out\n",
    "#SBATCH -e blast_%j.err\n",
    "\n",
    "blastx -query subset10_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset10_Trinity_fixed.fasta.br\n",
    "blastx -query subset11_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset11_Trinity_fixed.fasta.br\n",
    "blastx -query subset12_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset12_Trinity_fixed.fasta.br\n",
    "blastx -query subset13_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset13_Trinity_fixed.fasta.br\n",
    "blastx -query subset14_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset14_Trinity_fixed.fasta.br\n",
    "blastx -query subset15_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset15_Trinity_fixed.fasta.br\n",
    "blastx -query subset16_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset16_Trinity_fixed.fasta.br\n",
    "blastx -query subset17_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset17_Trinity_fixed.fasta.br\n",
    "blastx -query subset18_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset18_Trinity_fixed.fasta.br\n",
    "blastx -query subset19_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset19_Trinity_fixed.fasta.br\n",
    "blastx -query subset1_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset1_Trinity_fixed.fasta.br\n",
    "blastx -query subset20_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset20_Trinity_fixed.fasta.br\n",
    "blastx -query subset21_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset21_Trinity_fixed.fasta.br\n",
    "blastx -query subset22_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset22_Trinity_fixed.fasta.br\n",
    "blastx -query subset23_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset23_Trinity_fixed.fasta.br\n",
    "blastx -query subset24_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset24_Trinity_fixed.fasta.br\n",
    "blastx -query subset25_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset25_Trinity_fixed.fasta.br\n",
    "blastx -query subset26_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset26_Trinity_fixed.fasta.br\n",
    "blastx -query subset27_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset27_Trinity_fixed.fasta.br\n",
    "blastx -query subset28_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset28_Trinity_fixed.fasta.br\n",
    "blastx -query subset29_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset29_Trinity_fixed.fasta.br\n",
    "blastx -query subset2_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset2_Trinity_fixed.fasta.br\n",
    "blastx -query subset30_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset30_Trinity_fixed.fasta.br\n",
    "blastx -query subset31_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset31_Trinity_fixed.fasta.br\n",
    "blastx -query subset32_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset32_Trinity_fixed.fasta.br\n",
    "blastx -query subset33_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset33_Trinity_fixed.fasta.br\n",
    "blastx -query subset34_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset34_Trinity_fixed.fasta.br\n",
    "blastx -query subset35_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset35_Trinity_fixed.fasta.br\n",
    "blastx -query subset36_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset36_Trinity_fixed.fasta.br\n",
    "blastx -query subset37_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset37_Trinity_fixed.fasta.br\n",
    "blastx -query subset38_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset38_Trinity_fixed.fasta.br\n",
    "blastx -query subset39_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset39_Trinity_fixed.fasta.br\n",
    "blastx -query subset3_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset3_Trinity_fixed.fasta.br\n",
    "blastx -query subset40_Trinity_fixed.fasta -db uniprot_sprot.fasta -evalue 0.0001 -num_threads 3 -num_descriptions 5 -num_alignments 5 -out subset40_Trinity_fixed.fasta.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beafb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "chmod a+x blast.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ffffe8",
   "metadata": {},
   "source": [
    "Once your script is executable, submit the script to the job manager using the `sbatch` command. The output from this script should be files ending in `.br` for each of the 40 subsets. Once that script has finished running, we concatenate those files together into a single output file titled `myblast.br`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b70358",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat subset*br > myblast.br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699d926",
   "metadata": {},
   "source": [
    "After concatenating the output file you can either delete the subset files using the `rm` command, or you can organize them into a separate folder as done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2de7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir subsets\n",
    "mv subset*_* subsets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ac77c",
   "metadata": {},
   "source": [
    "### Annotating transcriptome with isogroup\n",
    "For transcriptomes assembled using Trinity, the assembled transcriptome file needs to be annotated with the isogroup, which we can do using the following `grep` and `cat` commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592de7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep \">\" tr.fasta | perl -pe 's/>((TRINITY.+_g\\d+)\\S+)/$1\\t$2/' >transcriptome_seq2iso.tab \n",
    "cat transcriptome.fasta | perl -pe 's/>((TRINITY.+_g\\d+)\\S+)/>$1 gene=$2/' >transcriptome_iso.fasta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
